{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yalopez84/Interpretable_method/blob/master/Triple_Prediction_FB_KG_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDjeSUVF90E_",
        "outputId": "d4d81d3c-c1c2-4df8-8ea0-cfa63668cb9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2022.6.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.24.14)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.1.1)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.14 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.27.14)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.14->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.14->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.14->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-pretrained-bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "fp2OLiKv-Lc9"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import argparse\n",
        "import csv\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from shutil import rmtree\n",
        "import pdb\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm, trange\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.metrics import matthews_corrcoef, f1_score\n",
        "from sklearn import metrics\n",
        "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE, WEIGHTS_NAME, CONFIG_NAME\n",
        "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig\n",
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3Gw7Hoe-Wvg",
        "outputId": "f889545e-9a5f-413f-fe86-a6a1aa9ea503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "W5Vf_9OECj1W"
      },
      "outputs": [],
      "source": [
        "data_dir=\"/content/drive/MyDrive/Almacen_phd/FB13/\"\n",
        "os.chdir(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0kCieQ1_lLp"
      },
      "source": [
        "# Preprocessing-Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "DWHVo81E-dSu"
      },
      "outputs": [],
      "source": [
        "class InputExample(object):\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, text_c=None, label=None):\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.text_c = text_c\n",
        "        self.label = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "OvnO2FaA-hc6"
      },
      "outputs": [],
      "source": [
        "class Triple(object):\n",
        "    def __init__(self, guid, subject , predicate , obj, label):\n",
        "        self.guid=guid\n",
        "        self.subject=subject\n",
        "        self.predicate=predicate\n",
        "        self.obj=obj\n",
        "        self.label=label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "OfN0RG0F-jt5"
      },
      "outputs": [],
      "source": [
        "class InputFeatures(object):\n",
        "    \n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_id = label_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "dtsQkRPI-m84"
      },
      "outputs": [],
      "source": [
        "class TripleEvaluationReport(object):\n",
        "    \n",
        "    def __init__(self, id_triple, id_label, id_prediction):\n",
        "        self.id_triple = id_triple\n",
        "        self.id_label = id_label\n",
        "        self.id_prediction = id_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "okHGmBaD-ojW"
      },
      "outputs": [],
      "source": [
        "class DataProcessor(object):\n",
        "  \n",
        "    def get_train_examples(self, data_dir):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_labels(self, data_dir):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "            lines = []\n",
        "            for line in reader:\n",
        "                lines.append(line)\n",
        "            return lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "UH5F-TyZ-zUq"
      },
      "outputs": [],
      "source": [
        "class KGProcessor(DataProcessor):\n",
        "    def __init__(self):\n",
        "        self.labels = set()\n",
        "    \n",
        "    def get_train_examples(self, data_dir):\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"train_reduced.tsv\")), \"train\", data_dir)\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\", data_dir)\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        return self._create_examples(\n",
        "          self._read_tsv(os.path.join(data_dir, \"test_reduced.tsv\")), \"test\", data_dir)\n",
        "\n",
        "    def get_relations(self, data_dir):\n",
        "        with open(os.path.join(data_dir, \"relations.txt\"), 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            relations = []\n",
        "            for line in lines:\n",
        "                relations.append(line.strip())\n",
        "        return relations\n",
        "\n",
        "    def get_labels(self, data_dir):\n",
        "        return [\"0\", \"1\"]\n",
        "\n",
        "    def get_entities(self, data_dir):\n",
        "        with open(os.path.join(data_dir, \"entities.txt\"), 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            entities = []\n",
        "            for line in lines:\n",
        "                entities.append(line.strip())\n",
        "        return entities\n",
        "\n",
        "    def get_train_triples(self, data_dir):\n",
        "        return self._read_tsv(os.path.join(data_dir, \"train.tsv\"))\n",
        "\n",
        "    def get_dev_triples(self, data_dir):\n",
        "        return self._read_tsv(os.path.join(data_dir, \"dev.tsv\"))\n",
        "\n",
        "    def get_test_triples(self, data_dir):\n",
        "        return self._read_tsv(os.path.join(data_dir, \"test.tsv\"))\n",
        "\n",
        "    def _create_examples(self, lines, set_type, data_dir):\n",
        "\n",
        "        train_with_corrupts=[] \n",
        "        id_Triple=\"\"\n",
        "        subject=\"\"\n",
        "        predicate=\"\"\n",
        "        obj=\"\"\n",
        "        id_Triple_corrupt=\"\"\n",
        "        subject_Triple_corrupt=\"\"\n",
        "        predicate_Triple_corrupt=\"\"\n",
        "        obj_Triple_corrupt=\"\"\n",
        "\n",
        "        ent2text = {}\n",
        "        with open(os.path.join(data_dir, \"entity2text.txt\"), 'r') as f:\n",
        "            ent_lines = f.readlines()\n",
        "            for line in tqdm(ent_lines):\n",
        "                temp = line.strip().split('\\t')\n",
        "                if len(temp) == 2:\n",
        "                    ent2text[temp[0]] = temp[1]\n",
        "\n",
        "        entities = list(ent2text.keys())\n",
        "\n",
        "        rel2text = {}\n",
        "        with open(os.path.join(data_dir, \"relation2text.txt\"), 'r') as f:\n",
        "            rel_lines = f.readlines()\n",
        "            for line in rel_lines:\n",
        "                temp = line.strip().split('\\t')\n",
        "                rel2text[temp[0]] = temp[1]      \n",
        "\n",
        "        lines_str_set = set(['\\t'.join(line) for line in lines])\n",
        "        examples = []        \n",
        "\n",
        "        for (i, line) in enumerate(lines):\n",
        "            auxiliar=[\"loke_joseph_of_austria_palatine_of_hungary\",\"united_srena_gale\"]\n",
        "            flag_aux=False\n",
        "\n",
        "            if line[0] or line[2] not in auxiliar:\n",
        "                head_ent_text = ent2text[line[0]]\n",
        "                tail_ent_text = ent2text[line[2]]\n",
        "                relation_text = rel2text[line[1]]          \n",
        "                flag_aux=True\n",
        "            else:\n",
        "                head_ent_text = line[0]\n",
        "                tail_ent_text = line[2]\n",
        "                relation_text = line[1]\n",
        "                flag_aux=True\n",
        "\n",
        "            if set_type == \"dev\" or set_type == \"test\" and flag_aux:\n",
        "                triple_label = line[3]\n",
        "                if triple_label == \"1\":\n",
        "                    label = \"1\"\n",
        "                else:\n",
        "                    label = \"0\"\n",
        "\n",
        "                guid = \"%s-%s\" % (set_type, i)\n",
        "                text_a = head_ent_text\n",
        "                text_b = relation_text\n",
        "                text_c = tail_ent_text \n",
        "                self.labels.add(label)\n",
        "                examples.append(\n",
        "                    InputExample(guid=guid, text_a=text_a, text_b=text_b, text_c = text_c, label=label))\n",
        "                \n",
        "            elif set_type == \"train\" and flag_aux:\n",
        "                guid = \"%s-%s\" % (set_type, i)\n",
        "                text_a = head_ent_text\n",
        "                text_b = relation_text\n",
        "                text_c = tail_ent_text \n",
        "\n",
        "                id_Triple=guid\n",
        "                subject=line[0]\n",
        "                predicate=line[1]\n",
        "                obj=line[2]\n",
        "                train_with_corrupts.append(Triple(guid=id_Triple,subject= subject, predicate=predicate, obj=obj, label=\"1\"))\n",
        "\n",
        "                examples.append(\n",
        "                    InputExample(guid=guid, text_a=text_a, text_b=text_b, text_c = text_c, label=\"1\"))\n",
        "\n",
        "                rnd = random.random()\n",
        "                guid = \"%s-%s\" % (set_type + \"_corrupt\", i)\n",
        "                if rnd <= 0.5:\n",
        "                    # corrupting head\n",
        "                    tmp_head = ''\n",
        "                    while True:\n",
        "                        tmp_ent_list = set(entities)\n",
        "                        tmp_ent_list.remove(line[0])\n",
        "                        tmp_ent_list = list(tmp_ent_list)\n",
        "                        tmp_head = random.choice(tmp_ent_list)\n",
        "                        tmp_triple_str = tmp_head + '\\t' + line[1] + '\\t' + line[2]\n",
        "                        if tmp_triple_str not in lines_str_set:\n",
        "                            break                    \n",
        "                    tmp_head_text = ent2text[tmp_head]\n",
        "\n",
        "                    id_Triple_corrupt=guid\n",
        "                    subject_Triple_corrupt=tmp_head\n",
        "                    predicate_Triple_corrupt=line[1]\n",
        "                    obj_Triple_corrupt=line[2]\n",
        "                    train_with_corrupts.append(Triple(guid=id_Triple_corrupt,subject=subject_Triple_corrupt, predicate=predicate_Triple_corrupt, obj=obj_Triple_corrupt, label=\"0\"))\n",
        "                    \n",
        "                    examples.append(\n",
        "                        InputExample(guid=guid, text_a=tmp_head_text, text_b=text_b, text_c = text_c, label=\"0\"))       \n",
        "                else:\n",
        "                    # corrupting tail\n",
        "                    tmp_tail = ''\n",
        "                    while True:\n",
        "                        tmp_ent_list = set(entities)\n",
        "                        tmp_ent_list.remove(line[2])\n",
        "                        tmp_ent_list = list(tmp_ent_list)\n",
        "                        tmp_tail = random.choice(tmp_ent_list)\n",
        "                        tmp_triple_str = line[0] + '\\t' + line[1] + '\\t' + tmp_tail\n",
        "                        if tmp_triple_str not in lines_str_set:\n",
        "                            break\n",
        "                    tmp_tail_text = ent2text[tmp_tail]\n",
        "\n",
        "                    id_Triple_corrupt=guid\n",
        "                    subject_Triple_corrupt=line[0]\n",
        "                    predicate_Triple_corrupt=line[1]\n",
        "                    obj_Triple_corrupt=tmp_tail\n",
        "                    train_with_corrupts.append(Triple(guid=id_Triple_corrupt,subject= subject_Triple_corrupt, predicate=predicate_Triple_corrupt, obj=obj_Triple_corrupt, label=\"0\"))\n",
        "                    \n",
        "                    examples.append(\n",
        "                        InputExample(guid=guid, text_a=text_a, text_b=text_b, text_c = tmp_tail_text, label=\"0\"))     \n",
        "        \n",
        "        if set_type == \"train\":\n",
        "            train_with_negatives_file=os.path.join(data_dir, \"train_reduced_with_negatives.txt\")\n",
        "            with open(train_with_negatives_file, \"w\") as writer:\n",
        "                for triple in train_with_corrupts:\n",
        "                    writer.write(\"%s %s %s %s %s\\n\" % (triple.guid, triple.subject, triple.predicate, triple.obj, triple.label))\n",
        "                                                            \n",
        "        return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "TXhwmowX-8es"
      },
      "outputs": [],
      "source": [
        "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, print_info = True):\n",
        "    \n",
        "    label_map = {label : i for i, label in enumerate(label_list)}\n",
        "\n",
        "    features = []\n",
        "    logger.info(\"\")\n",
        "    logger.info(\"Writing examples converted to features\")\n",
        "    logger.info(\"max_seq_length %d\" % (max_seq_length))\n",
        "\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        \n",
        "        tokens_a = tokenizer.tokenize(example.text_a)\n",
        "        tokens_b = None\n",
        "        tokens_c = None\n",
        "\n",
        "        if example.text_b and example.text_c:\n",
        "            tokens_b = tokenizer.tokenize(example.text_b)\n",
        "            tokens_c = tokenizer.tokenize(example.text_c)\n",
        "            _truncate_seq_triple(tokens_a, tokens_b, tokens_c, max_seq_length - 4)\n",
        "        else:\n",
        "            if len(tokens_a) > max_seq_length - 2:\n",
        "                tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
        "        segment_ids = [0] * len(tokens)\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens += tokens_b + [\"[SEP]\"]\n",
        "            segment_ids += [1] * (len(tokens_b) + 1)\n",
        "        if tokens_c:\n",
        "            tokens += tokens_c + [\"[SEP]\"]\n",
        "            segment_ids += [0] * (len(tokens_c) + 1)        \n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        padding = [0] * (max_seq_length - len(input_ids))\n",
        "        input_ids += padding\n",
        "        input_mask += padding\n",
        "        segment_ids += padding\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "\n",
        "        label_id = label_map[example.label]\n",
        "\n",
        "        if ex_index < 2 and print_info:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"tokens: %s\" % \" \".join(\n",
        "                    [str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "            logger.info(\n",
        "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
        "\n",
        "        features.append(\n",
        "                InputFeatures(input_ids=input_ids,\n",
        "                              input_mask=input_mask,\n",
        "                              segment_ids=segment_ids,\n",
        "                              label_id=label_id))\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "6JAWn0CZ_Bv-"
      },
      "outputs": [],
      "source": [
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "zuA2pKfp_ENa"
      },
      "outputs": [],
      "source": [
        "def _truncate_seq_triple(tokens_a, tokens_b, tokens_c, max_length):\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b) + len(tokens_c)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b) and len(tokens_a) > len(tokens_c):\n",
        "            tokens_a.pop()\n",
        "        elif len(tokens_b) > len(tokens_a) and len(tokens_b) > len(tokens_c):\n",
        "            tokens_b.pop()\n",
        "        elif len(tokens_c) > len(tokens_a) and len(tokens_c) > len(tokens_b):\n",
        "            tokens_c.pop()\n",
        "        else:\n",
        "            tokens_c.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "YGGZ-fHE_HVl"
      },
      "outputs": [],
      "source": [
        "def simple_accuracy(preds, labels):\n",
        "    return (preds == labels).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "bL_cPw4q_JYw"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(task_name, preds, labels):\n",
        "    \n",
        "    assert len(preds) == len(labels)\n",
        "    if task_name == \"kg\":\n",
        "        return {\"acc\": simple_accuracy(preds, labels)}\n",
        "    else:\n",
        "        raise KeyError(task_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "DfyY-l4kB5e3"
      },
      "outputs": [],
      "source": [
        "def createFBReduced(test_start,test_end,test_step,train_start,train_end,train_step):\n",
        "    #To reduce FB dataset \n",
        "    #train.tsv has 316219 triples, train_reduced.tsv has a subset of 11082 triples\n",
        "    #test.tsv has 47464, test_reduced has a sub set of 2253 triples  \n",
        "\n",
        "    processor = KGProcessor()\n",
        "    test_lines=processor._read_tsv(os.path.join(data_dir, \"test.tsv\"))\n",
        "    train_lines=processor._read_tsv(os.path.join(data_dir, \"train.tsv\")) \n",
        "\n",
        "    triples_train_reduced=processor._read_tsv(os.path.join(data_dir, \"train_reduced.tsv\"))\n",
        "    triples_test_reduced=processor._read_tsv(os.path.join(data_dir, \"test_reduced.tsv\"))\n",
        "    flag=False\n",
        "\n",
        "    for test_line in tqdm(test_lines[3000:4000:2]):\n",
        "        tests_str_set = set([' '.join(line) for line in triples_test_reduced])\n",
        "        flag=False\n",
        "        count=0\n",
        "        for train_line in train_lines[30000:60000]:\n",
        "            trains_str_set = set([' '.join(line) for line in triples_train_reduced])\n",
        "            if test_line[0] in train_line or test_line[1] in train_line or test_line[2] in train_line:\n",
        "                if ' '.join(train_line) not in trains_str_set:\n",
        "                    triples_train_reduced.append(train_line) \n",
        "                    flag=True\n",
        "                    count=count+1\n",
        "                    if count>=2:\n",
        "                        break\n",
        "        if flag==True:\n",
        "            if ' '.join(test_line) not in tests_str_set:\n",
        "                triples_test_reduced.append(test_line) \n",
        "\n",
        "    print(\"train_reduced\", len(triples_train_reduced),\"\\n\")\n",
        "    print(\"train_reduced\", triples_train_reduced,\"\\n\")\n",
        "\n",
        "    print(\"test_reduced\", len(triples_test_reduced),\"\\n\")\n",
        "    print(\"test_reduced\", triples_test_reduced,\"\\n\")\n",
        "\n",
        "    positivos=[triple for triple in triples_test_reduced if triple[3]==\"1\"]\n",
        "    negativos=[triple for triple in triples_test_reduced if triple[3]==\"-1\"]\n",
        "    print(\"positivos\", len(positivos),\"\\n\")\n",
        "    print(\"negativos\", len(negativos),\"\\n\")\n",
        "\n",
        "    with open(os.path.join(data_dir, \"train_reduced.tsv\"), \"w\") as writer:\n",
        "        for triple_ in triples_train_reduced:\n",
        "            writer.write('\\t'.join(triple_)+\"\\n\")\n",
        "\n",
        "    with open(os.path.join(data_dir, \"test_reduced.tsv\"), \"w\") as writer:\n",
        "        for triple_ in triples_test_reduced:\n",
        "            writer.write('\\t'.join(triple_)+\"\\n\")\n",
        "\n",
        "#createFBReduced(test_start=0,test_end=0,test_step=0,train_start=0,train_end=0,train_step=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfsVXOfV_OjY"
      },
      "source": [
        "# Preprocessing-End"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "GeX1izin_4n1"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "\n",
        "    arg_dict ={\n",
        "        \"task_name\": \"kg\",\n",
        "        \"do_train\": False,\n",
        "        \"do_eval\": False,\n",
        "        \"do_predict\":True,\n",
        "        \"data_dir\": data_dir,\n",
        "        \"bert_model\": \"bert-base-cased\",\n",
        "        \"max_seq_length\": 200,\n",
        "        \"train_batch_size\": 32,\n",
        "        \"eval_batch_size\": 512,\n",
        "        \"learning_rate\": 5e-5,\n",
        "        \"num_train_epochs\": 3.0,\n",
        "        \"output_dir\": \"./output_FB13/\",               \n",
        "        \"gradient_accumulation_steps\": 1,\n",
        "        \"seed\":42,\n",
        "        \"do_lower_case\":False,\n",
        "        \"loss_scale\":0,\n",
        "        \"warmup_proportion\":0.1\n",
        "        }\n",
        "\n",
        "    processors = {\n",
        "        \"kg\": KGProcessor,\n",
        "    }  \n",
        "\n",
        "    if os.path.exists(arg_dict[\"output_dir\"]) and arg_dict[\"do_train\"]:\n",
        "        rmtree(arg_dict[\"output_dir\"])\n",
        "        os.makedirs(arg_dict[\"output_dir\"])\n",
        "\n",
        "    logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                        datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                        level = logging.INFO)\n",
        "    n_gpu=0\n",
        "    device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "   \n",
        "    if str(device)==\"cuda\":\n",
        "        n_gpu=1\n",
        "    logger.info(\"device: {}\".format(device))  \n",
        "    arg_dict[\"seed\"] = random.randint(1, 200)\n",
        "    random.seed(arg_dict[\"seed\"])\n",
        "    np.random.seed(arg_dict[\"seed\"])\n",
        "    torch.manual_seed(arg_dict[\"seed\"])\n",
        "\n",
        "    if n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(arg_dict[\"seed\"])\n",
        "\n",
        "    task_name = arg_dict[\"task_name\"].lower()\n",
        "\n",
        "    if task_name not in processors:\n",
        "        raise ValueError(\"Task not found: %s\" % (task_name))\n",
        "\n",
        "    processor = processors[task_name]()\n",
        "\n",
        "    label_list = processor.get_labels(arg_dict[\"data_dir\"])\n",
        "    num_labels=len(label_list)\n",
        "    logger.info(\"num_labels: {}\".format(num_labels))   \n",
        "    logger.info(\"labels: {}\".format(label_list))  \n",
        "    \n",
        "    entity_list = processor.get_entities(arg_dict[\"data_dir\"])   \n",
        "    logger.info(\"entity_list: {}\".format(len(entity_list))) \n",
        "    \n",
        "    relation_list = processor.get_relations(arg_dict[\"data_dir\"])   \n",
        "    logger.info(\"relation_list: {}\".format(len(relation_list)))  \n",
        "   \n",
        "    logger.info(\"  \") \n",
        "    logger.info(\"//*************Tokenizer-start*************//\")   \n",
        "    tokenizer = BertTokenizer.from_pretrained(arg_dict[\"bert_model\"], do_lower_case=arg_dict[\"do_lower_case\"])\n",
        "    logger.info(\"//*************Tokenizer-end*************//\")   \n",
        "\n",
        "    train_examples = None\n",
        "    num_train_optimization_steps = 0\n",
        "\n",
        "    if arg_dict[\"do_train\"]:\n",
        "        train_examples = processor.get_train_examples(arg_dict[\"data_dir\"])\n",
        "\n",
        "        num_train_optimization_steps = int(\n",
        "            len(train_examples) / arg_dict[\"train_batch_size\"] / arg_dict[\"gradient_accumulation_steps\"]) * arg_dict[\"num_train_epochs\"]\n",
        "        logger.info(\"Num train optimization steps: {}\".format(num_train_optimization_steps)) \n",
        "    \n",
        "    logger.info(\"  \") \n",
        "    logger.info(\"//*************Prepare model-start*************//\")   \n",
        "    model = BertForSequenceClassification.from_pretrained(arg_dict[\"bert_model\"],\n",
        "              num_labels=num_labels)\n",
        "    model.to(device) \n",
        "    logger.info(\"//*************Prepare model-end*************//\")  \n",
        "\n",
        "    # Prepare optimizer\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "   \n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                         lr=arg_dict[\"learning_rate\"],\n",
        "                         warmup=arg_dict[\"warmup_proportion\"],\n",
        "                         t_total=num_train_optimization_steps)\n",
        "\n",
        "    global_step = 0\n",
        "    nb_tr_steps = 0\n",
        "    tr_loss = 0\n",
        "\n",
        "#Training\n",
        "    if arg_dict[\"do_train\"]: \n",
        "        logger.info(\"  \") \n",
        "        logger.info(\"//*************Running training start*************//\") \n",
        "\n",
        "        train_features = convert_examples_to_features(\n",
        "            train_examples, label_list, arg_dict[\"max_seq_length\"], tokenizer)\n",
        "\n",
        "        logger.info(\"           Num examples = %d\", len(train_examples))\n",
        "        logger.info(\"           Batch size = %d\", arg_dict[\"train_batch_size\"])\n",
        "        logger.info(\"           Num steps = %d\", num_train_optimization_steps)\n",
        "\n",
        "        all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
        "        all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
        "        all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
        "        all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
        "\n",
        "        train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "        train_sampler = RandomSampler(train_data)\n",
        "\n",
        "        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=arg_dict[\"train_batch_size\"])\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for epoch in trange(int(arg_dict[\"num_train_epochs\"]), desc=\"Epoch\"):\n",
        "            tr_loss = 0\n",
        "            nb_tr_examples, nb_tr_steps = 0, 0\n",
        "            for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
        "                batch = tuple(t.to(device) for t in batch)\n",
        "                input_ids, input_mask, segment_ids, label_ids = batch\n",
        "\n",
        "                logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
        "\n",
        "\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits, label_ids)\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                tr_loss += loss.item()\n",
        "                nb_tr_examples += input_ids.size(0)\n",
        "                nb_tr_steps += 1\n",
        "                if (step + 1) % arg_dict[\"gradient_accumulation_steps\"] == 0:\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "                    global_step += 1\n",
        "            logger.info(\" Training loss in epoch %s es: %s\", epoch+1, tr_loss)\n",
        "           \n",
        "        model_to_save = model \n",
        "\n",
        "        # If we save using the predefined names, we can load using `from_pretrained`\n",
        "        output_model_file = os.path.join(arg_dict[\"output_dir\"], WEIGHTS_NAME)\n",
        "        output_config_file = os.path.join(arg_dict[\"output_dir\"], CONFIG_NAME)\n",
        "\n",
        "        torch.save(model_to_save.state_dict(), output_model_file)\n",
        "        model_to_save.config.to_json_file(output_config_file)\n",
        "        tokenizer.save_vocabulary(arg_dict[\"output_dir\"])\n",
        "        logger.info(\"//*************Running training end*************//\")\n",
        "\n",
        " #Evaluation       \n",
        "    if os.path.exists(arg_dict[\"output_dir\"]) and arg_dict[\"do_eval\"]: \n",
        "        logger.info(\"      \")\n",
        "        logger.info(\"//*************Running evaluation start*************//\")      \n",
        "        model = BertForSequenceClassification.from_pretrained(arg_dict[\"output_dir\"], num_labels=num_labels)\n",
        "        tokenizer = BertTokenizer.from_pretrained(arg_dict[\"output_dir\"], do_lower_case=arg_dict[\"do_lower_case\"])\n",
        "        model.to(device)\n",
        "\n",
        "        eval_examples = processor.get_dev_examples(arg_dict[\"data_dir\"])\n",
        "        eval_features = convert_examples_to_features(\n",
        "            eval_examples, label_list, arg_dict[\"max_seq_length\"], tokenizer)\n",
        "        \n",
        "\n",
        "        logger.info(\"       Num examples = %d\", len(eval_examples))\n",
        "        logger.info(\"       Batch size = %d\", arg_dict[\"eval_batch_size\"])\n",
        "\n",
        "        all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
        "        all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
        "        all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
        "        all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
        "\n",
        "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "        eval_sampler = SequentialSampler(eval_data)\n",
        "        eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=arg_dict[\"eval_batch_size\"])\n",
        "\n",
        "        eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        preds = []\n",
        "        model.eval()\n",
        "\n",
        "        for input_ids, input_mask, segment_ids, label_ids in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = input_ids.to(device)\n",
        "            input_mask = input_mask.to(device)\n",
        "            segment_ids = segment_ids.to(device)\n",
        "            label_ids = label_ids.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
        "\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            tmp_eval_loss = loss_fct(logits, label_ids)\n",
        "           \n",
        "            eval_loss += tmp_eval_loss.mean().item()\n",
        "            nb_eval_steps += 1\n",
        "            \n",
        "            if len(preds) == 0:\n",
        "                preds.append(logits.detach().cpu().numpy())\n",
        "            else:\n",
        "                preds[0] = np.append(preds[0], logits.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "        eval_loss = eval_loss / nb_eval_steps\n",
        "        preds = preds[0]\n",
        "\n",
        "        preds_ids = np.argmax(preds, axis=1) \n",
        "        result = compute_metrics(task_name, preds_ids, all_label_ids.numpy())\n",
        "\n",
        "\n",
        "        triples_Evaluation_Report = []\n",
        "        for cont, label in enumerate(all_label_ids.numpy()):\n",
        "            triples_Evaluation_Report.append(TripleEvaluationReport(\n",
        "                    id_triple = cont,\n",
        "                    id_label = label,\n",
        "                    id_prediction = preds_ids[cont]\n",
        "            ))\n",
        "       \n",
        "        result['eval_loss'] = eval_loss\n",
        "\n",
        "        logger.info(\"***** Eval results *****\")\n",
        "        logger.info(\"Fecha del reporte \"+str(datetime.now()))\n",
        "        logger.info(\"Estructura del reporte:  id_triple  label  prediction\")\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "\n",
        "        output_eval_file = os.path.join(arg_dict[\"output_dir\"], \"eval_results.txt\")\n",
        "        with open(output_eval_file, \"w\") as writer:\n",
        "            for triple_ in triples_Evaluation_Report:\n",
        "                writer.write(\"%d %d %d\\n\" % (triple_.id_triple,triple_.id_label, triple_.id_prediction))\n",
        "        logger.info(\"//*************Running evaluation end*************//\")\n",
        "\n",
        "#Prediction\n",
        "    if os.path.exists(arg_dict[\"output_dir\"]) and arg_dict[\"do_predict\"]:\n",
        "        logger.info(\"  \")\n",
        "        logger.info(\"//*************Running testing start*************//\")\n",
        "        model = BertForSequenceClassification.from_pretrained(arg_dict[\"output_dir\"], num_labels=num_labels)\n",
        "        tokenizer = BertTokenizer.from_pretrained(arg_dict[\"output_dir\"], do_lower_case=arg_dict[\"do_lower_case\"])\n",
        "        model.to(device)\n",
        "\n",
        "        test_examples = processor.get_test_examples(arg_dict[\"data_dir\"])\n",
        "\n",
        "        test_features = convert_examples_to_features(\n",
        "            test_examples, label_list, arg_dict[\"max_seq_length\"], tokenizer)\n",
        "\n",
        "        logger.info(\"       Num examples = %d\", len(test_examples))\n",
        "        logger.info(\"       Batch size = %d\", arg_dict[\"eval_batch_size\"])\n",
        "\n",
        "        all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
        "        all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
        "        all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
        "        all_label_ids = torch.tensor([f.label_id for f in test_features], dtype=torch.long)\n",
        "\n",
        "  \n",
        "        test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "        test_sampler = SequentialSampler(test_data)\n",
        "        test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=arg_dict[\"eval_batch_size\"])\n",
        "        print(test_dataloader.batch_size)\n",
        "       \n",
        "        \n",
        "        eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        preds = []\n",
        "        model.eval()\n",
        "\n",
        "        for input_ids, input_mask, segment_ids, label_ids in tqdm(test_dataloader, desc=\"Testing\"):\n",
        "            input_ids = input_ids.to(device)\n",
        "            input_mask = input_mask.to(device)\n",
        "            segment_ids = segment_ids.to(device)\n",
        "            label_ids = label_ids.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
        "\n",
        "\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            tmp_eval_loss = loss_fct(logits, label_ids)\n",
        "            \n",
        "            eval_loss += tmp_eval_loss.mean().item()\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "            if len(preds) == 0:\n",
        "                preds.append(logits.detach().cpu().numpy())        \n",
        "            else:\n",
        "                preds[0] = np.append(preds[0], logits.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "        eval_loss = eval_loss / nb_eval_steps\n",
        "        preds = preds[0]\n",
        "\n",
        "        preds_ids = np.argmax(preds, axis=1)\n",
        "        result = compute_metrics(task_name, preds_ids,all_label_ids.numpy())\n",
        "\n",
        "        triples_Evaluation_Report = []\n",
        "        for cont, label in enumerate(all_label_ids.numpy()):\n",
        "            triples_Evaluation_Report.append(TripleEvaluationReport(\n",
        "                    id_triple = cont,\n",
        "                    id_label = label,\n",
        "                    id_prediction = preds_ids[cont]\n",
        "            ))\n",
        "\n",
        "        result['eval_loss'] = eval_loss\n",
        "\n",
        "        logger.info(\"***** Test results *****\")\n",
        "        logger.info(\"Fecha del reporte \"+str(datetime.now()))\n",
        "        logger.info(\"Estructura del reporte:  id_triple  label  prediction\")\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "\n",
        "        output_test_file = os.path.join(arg_dict[\"output_dir\"], \"test_results.txt\")\n",
        "        with open(output_test_file, \"w\") as writer:           \n",
        "            for triple_ in triples_Evaluation_Report:\n",
        "                writer.write(\"%d %d %d\\n\" % (triple_.id_triple,triple_.id_label, triple_.id_prediction))\n",
        "        logger.info(\"//*************Running testing end*************//\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0vdOg14_7PO"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Triple_Prediction_FB_KG-BERT",
      "provenance": [],
      "authorship_tag": "ABX9TyNtPwMokfLk+qbxxd6elGw5",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}